{
  "paragraphs": [
    {
      "text": "%md\n### Initialize Spark Context and Spark SQL Context",
      "dateUpdated": "Oct 5, 2016 1:59:15 PM",
      "config": {
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "editorHide": true,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1475675955391_1539050677",
      "id": "20161005-135915_111932721",
      "result": {
        "code": "SUCCESS",
        "type": "HTML",
        "msg": "\u003ch3\u003eInitialize Spark Context and Spark SQL Context\u003c/h3\u003e\n"
      },
      "dateCreated": "Oct 5, 2016 1:59:15 PM",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%pyspark\nfrom pyspark.sql import SQLContext\nsc\n",
      "dateUpdated": "Oct 7, 2016 2:18:06 PM",
      "config": {
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1475675955391_1539050677",
      "id": "20161005-135915_1340486389",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": ""
      },
      "dateCreated": "Oct 5, 2016 1:59:15 PM",
      "dateStarted": "Oct 7, 2016 2:18:06 PM",
      "dateFinished": "Oct 7, 2016 2:18:06 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n### Creating DataFrames from JSON files",
      "dateUpdated": "Oct 5, 2016 1:59:15 PM",
      "config": {
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "editorHide": true,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1475675955392_1524814968",
      "id": "20161005-135915_1948290243",
      "result": {
        "code": "SUCCESS",
        "type": "HTML",
        "msg": "\u003ch3\u003eCreating DataFrames from JSON files\u003c/h3\u003e\n"
      },
      "dateCreated": "Oct 5, 2016 1:59:15 PM",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%pyspark\n\nusers \u003d sqlContext.read.json(\"/zeppelin/datasets/yelp/yelp_academic_dataset_user.json\")\nusers.registerTempTable(\"userTable\")",
      "dateUpdated": "Oct 7, 2016 2:18:08 PM",
      "config": {
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1475675955392_1524814968",
      "id": "20161005-135915_462807227",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": ""
      },
      "dateCreated": "Oct 5, 2016 1:59:15 PM",
      "dateStarted": "Oct 7, 2016 2:18:08 PM",
      "dateFinished": "Oct 7, 2016 2:18:15 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%sql\nselect review_count, count(*) as count from userTable group by review_count",
      "dateUpdated": "Oct 7, 2016 2:18:16 PM",
      "config": {
        "colWidth": 12.0,
        "editorMode": "ace/mode/sql",
        "graph": {
          "mode": "multiBarChart",
          "height": 300.0,
          "optionOpen": false,
          "keys": [
            {
              "name": "review_count",
              "index": 0.0,
              "aggr": "sum"
            }
          ],
          "values": [
            {
              "name": "count",
              "index": 1.0,
              "aggr": "sum"
            }
          ],
          "groups": [],
          "scatter": {
            "xAxis": {
              "name": "review_count",
              "index": 0.0,
              "aggr": "sum"
            }
          }
        },
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1475675955392_1524814968",
      "id": "20161005-135915_1112444037",
      "result": {
        "code": "ERROR",
        "type": "TEXT",
        "msg": "org.apache.spark.sql.AnalysisException: Table not found: userTable; line 1 pos 44\n\tat org.apache.spark.sql.catalyst.analysis.package$AnalysisErrorAt.failAnalysis(package.scala:42)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.getTable(Analyzer.scala:306)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$9.applyOrElse(Analyzer.scala:315)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$9.applyOrElse(Analyzer.scala:310)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan$$anonfun$resolveOperators$1.apply(LogicalPlan.scala:57)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan$$anonfun$resolveOperators$1.apply(LogicalPlan.scala:57)\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:53)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperators(LogicalPlan.scala:56)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan$$anonfun$1.apply(LogicalPlan.scala:54)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan$$anonfun$1.apply(LogicalPlan.scala:54)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$4.apply(TreeNode.scala:265)\n\tat scala.collection.Iterator$$anon$11.next(Iterator.scala:328)\n\tat scala.collection.Iterator$class.foreach(Iterator.scala:727)\n\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1157)\n\tat scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:48)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:103)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:47)\n\tat scala.collection.TraversableOnce$class.to(TraversableOnce.scala:273)\n\tat scala.collection.AbstractIterator.to(Iterator.scala:1157)\n\tat scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:265)\n\tat scala.collection.AbstractIterator.toBuffer(Iterator.scala:1157)\n\tat scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:252)\n\tat scala.collection.AbstractIterator.toArray(Iterator.scala:1157)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformChildren(TreeNode.scala:305)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperators(LogicalPlan.scala:54)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:310)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:300)\n\tat org.apache.spark.sql.catalyst.rules.RuleExecutor$$anonfun$execute$1$$anonfun$apply$1.apply(RuleExecutor.scala:83)\n\tat org.apache.spark.sql.catalyst.rules.RuleExecutor$$anonfun$execute$1$$anonfun$apply$1.apply(RuleExecutor.scala:80)\n\tat scala.collection.LinearSeqOptimized$class.foldLeft(LinearSeqOptimized.scala:111)\n\tat scala.collection.immutable.List.foldLeft(List.scala:84)\n\tat org.apache.spark.sql.catalyst.rules.RuleExecutor$$anonfun$execute$1.apply(RuleExecutor.scala:80)\n\tat org.apache.spark.sql.catalyst.rules.RuleExecutor$$anonfun$execute$1.apply(RuleExecutor.scala:72)\n\tat scala.collection.immutable.List.foreach(List.scala:318)\n\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:72)\n\tat org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:36)\n\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:36)\n\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:34)\n\tat org.apache.spark.sql.DataFrame.\u003cinit\u003e(DataFrame.scala:133)\n\tat org.apache.spark.sql.DataFrame$.apply(DataFrame.scala:52)\n\tat org.apache.spark.sql.SQLContext.sql(SQLContext.scala:817)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:483)\n\tat org.apache.zeppelin.spark.SparkSqlInterpreter.interpret(SparkSqlInterpreter.java:138)\n\tat org.apache.zeppelin.interpreter.ClassloaderInterpreter.interpret(ClassloaderInterpreter.java:57)\n\tat org.apache.zeppelin.interpreter.LazyOpenInterpreter.interpret(LazyOpenInterpreter.java:93)\n\tat org.apache.zeppelin.interpreter.remote.RemoteInterpreterServer$InterpretJob.jobRun(RemoteInterpreterServer.java:295)\n\tat org.apache.zeppelin.scheduler.Job.run(Job.java:171)\n\tat org.apache.zeppelin.scheduler.FIFOScheduler$1.run(FIFOScheduler.java:139)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n\tat java.lang.Thread.run(Thread.java:745)\n"
      },
      "dateCreated": "Oct 5, 2016 1:59:15 PM",
      "dateStarted": "Oct 7, 2016 2:18:16 PM",
      "dateFinished": "Oct 7, 2016 2:18:16 PM",
      "status": "ERROR",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%pyspark\nusers.printSchema()",
      "dateUpdated": "Oct 7, 2016 2:18:28 PM",
      "config": {
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1475675955398_1524045470",
      "id": "20161005-135915_1019309987",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": "root\n |-- average_stars: double (nullable \u003d true)\n |-- compliments: struct (nullable \u003d true)\n |    |-- cool: long (nullable \u003d true)\n |    |-- cute: long (nullable \u003d true)\n |    |-- funny: long (nullable \u003d true)\n |    |-- hot: long (nullable \u003d true)\n |    |-- list: long (nullable \u003d true)\n |    |-- more: long (nullable \u003d true)\n |    |-- note: long (nullable \u003d true)\n |    |-- photos: long (nullable \u003d true)\n |    |-- plain: long (nullable \u003d true)\n |    |-- profile: long (nullable \u003d true)\n |    |-- writer: long (nullable \u003d true)\n |-- elite: array (nullable \u003d true)\n |    |-- element: long (containsNull \u003d true)\n |-- fans: long (nullable \u003d true)\n |-- friends: array (nullable \u003d true)\n |    |-- element: string (containsNull \u003d true)\n |-- name: string (nullable \u003d true)\n |-- review_count: long (nullable \u003d true)\n |-- type: string (nullable \u003d true)\n |-- user_id: string (nullable \u003d true)\n |-- votes: struct (nullable \u003d true)\n |    |-- cool: long (nullable \u003d true)\n |    |-- funny: long (nullable \u003d true)\n |    |-- useful: long (nullable \u003d true)\n |-- yelping_since: string (nullable \u003d true)\n\n"
      },
      "dateCreated": "Oct 5, 2016 1:59:15 PM",
      "dateStarted": "Oct 7, 2016 2:18:28 PM",
      "dateFinished": "Oct 7, 2016 2:18:28 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n### Prepare data input for KMeans\n",
      "dateUpdated": "Oct 5, 2016 1:59:15 PM",
      "config": {
        "colWidth": 12.0,
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1475675955400_1521736976",
      "id": "20161005-135915_1291299436",
      "result": {
        "code": "SUCCESS",
        "type": "HTML",
        "msg": "\u003ch3\u003ePrepare data input for KMeans\u003c/h3\u003e\n"
      },
      "dateCreated": "Oct 5, 2016 1:59:15 PM",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%pyspark\nfrom pyspark.mllib.linalg import Vectors\n\n# Youtube video k-means tutorial https://www.youtube.com/watch?v\u003d_aWzGGNrcic\n# Coursera video tutorial : https://www.coursera.org/learn/machine-learning/home/week/8\n\nuserReviews \u003d users.map(lambda user : Row(user.user_id, user.name, user.average_stars, Vectors.dense([user.review_count])))\nuserReviewDF \u003d sqlContext.createDataFrame(userReviews, [\"user_id\", \"name\", \"average_stars\", \"features\"])\nuserReviewDF.cache()\nuserReviewDF.show(5)",
      "dateUpdated": "Oct 5, 2016 1:59:15 PM",
      "config": {
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1475675955401_1521352227",
      "id": "20161005-135915_2018712433",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": "+--------------------+---------+-------------+--------+\n|             user_id|     name|average_stars|features|\n+--------------------+---------+-------------+--------+\n|18kPq7GPye-YQ3LyK...|   Russel|         4.14| [108.0]|\n|rpOyqD_893cqmDAtJ...|   Jeremy|         3.66|[1274.0]|\n|4U9kSBLuBDU391x6b...|  Michael|          3.6| [442.0]|\n|fHtTaujcyKvXglE33...|      Ken|         4.64|  [11.0]|\n|SIBCL7HBkrP4llolm...|Katherine|          3.8|  [66.0]|\n+--------------------+---------+-------------+--------+\nonly showing top 5 rows\n\n"
      },
      "dateCreated": "Oct 5, 2016 1:59:15 PM",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n### Setup KMeans model\n",
      "dateUpdated": "Oct 5, 2016 1:59:15 PM",
      "config": {
        "colWidth": 12.0,
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1475675955401_1521352227",
      "id": "20161005-135915_1313835610",
      "result": {
        "code": "SUCCESS",
        "type": "HTML",
        "msg": "\u003ch3\u003eSetup KMeans model\u003c/h3\u003e\n"
      },
      "dateCreated": "Oct 5, 2016 1:59:15 PM",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%pyspark\nfrom pyspark.ml.clustering import KMeans\n\n# official docs : http://spark.apache.org/docs/latest/api/python/pyspark.ml.html#module-pyspark.ml.clustering\nkmeans \u003d KMeans(k\u003d10, initMode\u003d\"random\")\nmodel \u003d kmeans.fit(userReviewDF)\n\n\n",
      "dateUpdated": "Oct 5, 2016 1:59:15 PM",
      "config": {
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1475675955402_1522506474",
      "id": "20161005-135915_2034522183",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": ""
      },
      "dateCreated": "Oct 5, 2016 1:59:15 PM",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%pyspark\ncenters \u003d model.clusterCenters()\nprint centers\nresults \u003d model.transform(userReviewDF)\nresults.show(5)\nresults.registerTempTable(\"results\")",
      "dateUpdated": "Oct 5, 2016 1:59:15 PM",
      "config": {
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1475675955403_1522121725",
      "id": "20161005-135915_143735241",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": "[array([ 1407.06451613]), array([ 2.41099042]), array([ 532.88085827]), array([ 4.85601539]), array([ 21.36798704]), array([ 9.82310924]), array([ 105.57646294]), array([ 0.99987885]), array([ 235.05888494]), array([ 46.64435981])]\n+--------------------+---------+-------------+--------+----------+\n|             user_id|     name|average_stars|features|prediction|\n+--------------------+---------+-------------+--------+----------+\n|18kPq7GPye-YQ3LyK...|   Russel|         4.14| [108.0]|         6|\n|rpOyqD_893cqmDAtJ...|   Jeremy|         3.66|[1274.0]|         0|\n|4U9kSBLuBDU391x6b...|  Michael|          3.6| [442.0]|         2|\n|fHtTaujcyKvXglE33...|      Ken|         4.64|  [11.0]|         5|\n|SIBCL7HBkrP4llolm...|Katherine|          3.8|  [66.0]|         9|\n+--------------------+---------+-------------+--------+----------+\nonly showing top 5 rows\n\n"
      },
      "dateCreated": "Oct 5, 2016 1:59:15 PM",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%pyspark\nfrom math import sqrt\n# Evaluate clustering by computing Within Set Sum of Squared Errors\ndef error(point):\n    center \u003d centers[point[\"prediction\"]]\n    return sqrt(sum([x**2 for x in (point[\"features\"] - center)]))",
      "dateUpdated": "Oct 5, 2016 1:59:15 PM",
      "config": {
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1475675955404_1520197981",
      "id": "20161005-135915_1752769337",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": ""
      },
      "dateCreated": "Oct 5, 2016 1:59:15 PM",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%pyspark\nerrors \u003d results.map(lambda point : error(point)).reduce(lambda a,b : a + b)\nprint errors",
      "dateUpdated": "Oct 5, 2016 1:59:15 PM",
      "config": {
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1475675955404_1520197981",
      "id": "20161005-135915_1524001078",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": "3054290.14405\n"
      },
      "dateCreated": "Oct 5, 2016 1:59:15 PM",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%pyspark\nsqlContext.sql(\"select prediction, avg(average_stars) as avg_star from results group by prediction\").show()\nsqlContext.sql(\"select * from results where prediction \u003d 0\").show()",
      "dateUpdated": "Oct 5, 2016 1:59:15 PM",
      "config": {
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1475675955405_1519813232",
      "id": "20161005-135915_17536075",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": "+----------+------------------+\n|prediction|          avg_star|\n+----------+------------------+\n|         0|3.7545013239188014|\n|         1| 3.740673535945571|\n|         2|3.7304451510333876|\n+----------+------------------+\n\n+--------------------+---------+-------------+--------+----------+\n|             user_id|     name|average_stars|features|prediction|\n+--------------------+---------+-------------+--------+----------+\n|4U9kSBLuBDU391x6b...|  Michael|          3.6| [442.0]|         0|\n|za5Q2uYrTmky9w_3h...|   Steven|         4.05| [362.0]|         0|\n|eQ4PN9G8Q9ipqBxFr...|  Jannies|          3.8| [222.0]|         0|\n|wy6l_zUo7SN0qrvNR...|      Ryo|         3.52| [170.0]|         0|\n|T4kuUr_iJiywOPdyM...|    jenna|         4.13| [158.0]|         0|\n|qS8M-5H4XsI1wxGID...|    April|         3.62| [231.0]|         0|\n|dfkRRR7vHoF_0ApWj...|      Yue|         3.87| [383.0]|         0|\n|totSIgraA3tIEh2Kb...|     Phan|         3.52| [563.0]|         0|\n|kvWAieuO61gBdRfnA...|    Jason|         3.98| [246.0]|         0|\n|XpNYhS7EnzTozA4CA...|  Colleen|          3.5| [340.0]|         0|\n|o2CGc1kQHEFkYOECM...|Stephanie|         3.61| [306.0]|         0|\n|4JkYQOTrSTh4TahuM...|     Kate|         3.97| [210.0]|         0|\n|QEYTm3qf6Kmp0Vmam...|    Elyse|          3.7| [169.0]|         0|\n|YItwbAgVpuNU7O0Gd...|        C|         3.53| [221.0]|         0|\n|tCVQyYHcmOrx2i81C...|  Melissa|         3.91| [150.0]|         0|\n|rFESBu6i2hHmgQWYM...|   Ingrid|         3.62| [364.0]|         0|\n|W-VlJfTsCTBjknjIo...|     Tony|          3.4| [299.0]|         0|\n|wgGrT5bsh4Xtj9XB2...|    Marci|         4.38| [179.0]|         0|\n|z_5D4XEIlGAPjG3Os...|Christina|         3.96| [287.0]|         0|\n|Re447krbp0VQVX3Dk...|   Andrew|         3.88| [263.0]|         0|\n+--------------------+---------+-------------+--------+----------+\nonly showing top 20 rows\n\n"
      },
      "dateCreated": "Oct 5, 2016 1:59:15 PM",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "dateUpdated": "Oct 5, 2016 1:59:15 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1475675955405_1519813232",
      "id": "20161005-135915_14002898",
      "dateCreated": "Oct 5, 2016 1:59:15 PM",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    }
  ],
  "name": "SparkMLPythonDevTalksParticipants",
  "id": "2BX275WGU",
  "angularObjects": {
    "2BZHNY8YW": [],
    "2BXH27H7Y": [],
    "2BXSYDWQJ": [],
    "2BXVEEXUD": [],
    "2BZ3ZH5DD": [],
    "2BZVMRK3C": [],
    "2BXYUVPDU": [],
    "2BZF8WBGC": [],
    "2BWD4U18K": [],
    "2BY9TUPDW": [],
    "2BWQ2A68P": [],
    "2BY8CJRFY": [],
    "2BWNHA89P": [],
    "2BWC4685H": [],
    "2BZ2FXK85": []
  },
  "config": {},
  "info": {}
}